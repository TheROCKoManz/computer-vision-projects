{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_2000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_3000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_4000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_8000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_5000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_60.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_1000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_9000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_6000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_10000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_12000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_13000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_14000.jpg\n",
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_7000.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([-21.45748841,   7.15953527,   7.71336987,  -3.97872125,\n        -5.49927376,  -6.24811897,  -2.14720658,  -3.85390815,\n         9.76310293, -11.23288146,  20.93997992,  -4.32546395,\n       -19.75822215,  -4.87437729,  -3.08587374,   6.55252465,\n       -14.11122249, -13.54660408,  -4.01116289,  -8.1401103 ,\n         6.94360917,   0.35876222,  -4.26322616,   5.00536649,\n       -15.78307003, -38.32079172,  -5.54477635, -10.65466218,\n         3.77356421, -10.55864096,   0.04596736,   1.55760039,\n       -12.64916376,  -1.61802207,  -1.30536771,  11.77820345,\n         0.07125837,  -1.79396274,  17.76791417,  -2.30540563,\n       -15.56566773,  -5.27098197,   9.11648284,  29.64725154,\n        17.43142264,   7.09090325,   2.15333828,  -7.2804376 ,\n         8.75588278, -19.56646538,   6.10504029,  12.35304156,\n         9.51153404,   6.73814693,  10.61307149, -14.20023292,\n         2.61473863,   4.06969277, -17.8789158 ,   7.65199643,\n         1.98092795,  -5.48284168,  -1.64578086,  -2.41026963,\n        19.18469103,   6.12235667,  -9.69655748, -10.82975928,\n        14.23688456, -23.19387357,  -5.96417202,   6.07444404,\n        -5.85690626, -18.13341422, -25.5179782 ,   4.08144257,\n        35.77137973,  21.3150745 , -14.15883409,   5.61924017,\n        -2.90114439, -10.07900749,  13.88930428,  10.11008393,\n       -10.89184455,   2.02949615, -10.08491394,   6.12641319,\n        17.68895388,   6.47614537,  -3.09921554,  15.09194353,\n         1.01339284,   2.90800411,   5.40227451,   3.58933218,\n       -16.80780553,   2.66909357, -10.37837176,  -5.28666054,\n         8.28388357,  -5.52868859,   2.98124849,  10.87967328,\n       -16.10522334,  13.61699578,  -2.73389147,  -1.58046433,\n        -0.61368347,   4.7783786 ,  -9.21495485,  -4.50612235,\n        11.16747122, -19.9338782 ,  12.26799765,  18.56525104,\n         3.94312876,  16.01205899,  12.44419558,   1.71090121,\n         3.5275334 ,  -0.45015928, -16.03386993,  -2.6724322 ,\n         0.41520055,  -3.95294961,  10.74065539,   1.67889234])"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_average_face_encoding_from_folder(folder_path):\n",
    "    all_face_encodings = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            face_encodings = face_recognition.face_encodings(image)\n",
    "            print(image_path)\n",
    "            for encoding in face_encodings:\n",
    "                all_face_encodings.append(encoding)\n",
    "\n",
    "    if all_face_encodings:\n",
    "        average_encoding = sum(all_face_encodings) / len(all_face_encodings)\n",
    "        return np.array(average_encoding)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Specify the path to the folder containing images of the person\n",
    "folder_path = target\n",
    "\n",
    "# Get the average face encoding from the folder\n",
    "person_average_encoding = [get_average_face_encoding_from_folder(folder_path)]\n",
    "\n",
    "person_average_encoding[0]*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T08:47:56.202577498Z",
     "start_time": "2023-08-12T08:47:54.660271162Z"
    }
   },
   "id": "39b9bd223724e9bb"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "person_average_encoding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T08:46:21.883599746Z",
     "start_time": "2023-08-12T08:46:21.839840833Z"
    }
   },
   "id": "8315259511e0ea45"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 14:24:13.777924: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-12 14:24:13.915850: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-08-12 14:24:14.363100: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/manz/miniconda3/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-08-12 14:24:14.363215: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/manz/miniconda3/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-08-12 14:24:14.363227: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision\n",
      "\n",
      "\n",
      "Training_Mode_ON\n",
      "\n",
      "\n",
      "Downloading Training Videos...\n",
      "\n",
      "Downloading video of 10010...\n",
      "Downloaded video of 10010...\n",
      "\n",
      "\n",
      "Downloading video of 10010...\n",
      "Downloaded video of 10010...\n",
      "\n",
      "\n",
      "Downloading video of 10019...\n",
      "Downloaded video of 10019...\n",
      "\n",
      "Raw videos downloaded for training.\n",
      "\n",
      "Extracting Frames from Videos...\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/1001060.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/100101000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/100102000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/100103000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/100104000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/100105000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/100106000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/100107000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/100108000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/100109000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/1001010000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/1001012000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/1001013000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/1001014000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100191000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100192000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100195000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100196000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100197000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100199000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/1001910000.jpg\n",
      "Frames Extracted\n"
     ]
    }
   ],
   "source": [
    "from Face_Recog.DataPreproc import Preprocess, extractFrames\n",
    "from Face_Recog.Server_Loading import Download_from_Server as DFS\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "# Append the repository root to sys.path\n",
    "os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "def train(Targets):\n",
    "    print('\\n\\nTraining_Mode_ON\\n')\n",
    "    # delete_localfiles()\n",
    "    DFS.download_videos(Targets)\n",
    "    extractFrames.extractFrames(Targets)\n",
    "    \n",
    "    # delete_localfiles('image_base_dir')\n",
    "    # Data = Preprocess.preprocess(Targets)\n",
    "    # delete_localfiles('work_dir')\n",
    "    # Model_ID = TrainModel.train(Data)\n",
    "    # delete_localfiles()\n",
    "\n",
    "\n",
    "train(['10010','10019'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T08:54:25.374256286Z",
     "start_time": "2023-08-12T08:54:13.459291359Z"
    }
   },
   "id": "23baf4055e592c9b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "import cv2\n",
    "target = '/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T09:22:06.685629859Z",
     "start_time": "2023-08-12T09:22:06.681711519Z"
    }
   },
   "id": "1a72d490a5571edc"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-20.67381665,   8.20198671,   7.28124101,  -4.58076878,\n        -5.90276689,  -5.75466546,  -2.41947573,  -6.24777052,\n        11.21629642, -12.57852422,  18.45900491,  -2.25796747,\n       -19.28898799,  -3.98456426,  -3.1411696 ,   7.71815021,\n       -13.83971497, -13.99297113,  -4.93439389,  -8.0293628 ,\n         6.8409577 ,   1.21449932,  -3.48151942,   2.80930532,\n       -14.28751828, -38.29967656,  -6.44887127,  -9.55551251,\n         4.27720955,  -8.66276161,   0.52017407,   0.86698735,\n       -12.9313818 ,  -0.58594544,  -2.67019728,  12.33001841,\n        -1.66027262,  -2.91176801,  17.49506848,  -0.43868739,\n       -15.68133118,  -5.09390514,   8.06987685,  28.17072975,\n        17.77814307,   5.84977269,   3.30637741,  -7.74819878,\n         8.27394224, -18.37866477,   4.08350793,  11.59785156,\n         8.98793308,   8.69709421,  10.09519616, -14.30706467,\n         4.05578873,   4.10427955, -18.83091788,   7.89800558,\n         2.25323395,  -6.47655163,  -1.95775819,  -1.8689005 ,\n        19.04718237,   7.25957904,  -8.51622038, -10.81472917,\n        14.76749985, -23.56134834,  -6.88296203,   4.38886725,\n        -6.48000858, -17.9580093 , -26.05673447,   2.01509425,\n        35.37326668,  22.46211086, -12.78714862,   4.22803376,\n        -2.26212521,  -9.44321493,  14.2774038 ,  10.04504021,\n       -11.10877246,   2.04586548,  -9.37860635,   6.08835876,\n        18.32051916,   6.00766742,  -4.05227896,  15.8549511 ,\n         1.31626981,   4.27155378,   3.57413016,   3.39936244,\n       -15.39756006,   2.99047323,  -9.93939423,  -5.51302891,\n         7.39332547,  -6.75945349,   4.03924417,  10.82346737,\n       -15.4029099 ,  14.24363836,  -2.06992364,  -0.13200801,\n        -0.98328061,   5.49729152,  -9.71574225,  -3.78350957,\n        12.0297705 , -18.1507762 ,  13.92365196,  21.18458099,\n         2.62644787,  15.62322932,  12.52474285,   2.52046103,\n         2.20871749,  -0.76321734, -16.49286486,  -2.53488874,\n        -0.80375222,  -2.77285223,  10.6320668 ,   3.67750095])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def get_average_face_embedding_from_folder(folder_path):\n",
    "    all_face_embeddings = []\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = face_recognition.load_image_file(image_path)\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            # Detect facial landmarks\n",
    "            face_landmarks_list = face_recognition.face_landmarks(image)\n",
    "            \n",
    "            for landmarks in face_landmarks_list:\n",
    "                # Get facial landmarks\n",
    "                left_eye = landmarks['left_eye']\n",
    "                right_eye = landmarks['right_eye']\n",
    "                \n",
    "                # Calculate the center between the eyes for face alignment\n",
    "                eye_center = np.mean([left_eye[3], right_eye[0]], axis=0)\n",
    "                \n",
    "                # Calculate the rotation angle based on the eyes\n",
    "                dY = right_eye[0][1] - left_eye[3][1]\n",
    "                dX = right_eye[0][0] - left_eye[3][0]\n",
    "                angle = np.degrees(np.arctan2(dY, dX))\n",
    "                \n",
    "                # Rotate and align the face using PIL\n",
    "                pil_image = Image.fromarray(image)\n",
    "                aligned_face = pil_image.rotate(angle, center=tuple(eye_center))\n",
    "                aligned_face = np.array(aligned_face)\n",
    "                \n",
    "                # Compute face encoding for the aligned face\n",
    "                embedding = face_recognition.face_encodings(aligned_face)[0]\n",
    "                all_face_embeddings.append(embedding)\n",
    "\n",
    "    if all_face_embeddings:\n",
    "        average_embedding = np.mean(all_face_embeddings, axis=0)\n",
    "        return average_embedding\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_face_embedding_from_test_image(test_image_path):\n",
    "    # Load the test image\n",
    "    test_image = face_recognition.load_image_file(test_image_path)\n",
    "    test_image = cv2.cvtColor(test_image,cv2.COLOR_BGR2RGB)\n",
    "    # Detect facial landmarks\n",
    "    face_landmarks_list = face_recognition.face_landmarks(test_image)\n",
    "    \n",
    "    if not face_landmarks_list:\n",
    "        return None\n",
    "    \n",
    "    # Get facial landmarks\n",
    "    landmarks = face_landmarks_list[0]  # Assuming one face per image\n",
    "    left_eye = landmarks['left_eye']\n",
    "    right_eye = landmarks['right_eye']\n",
    "    \n",
    "    # Calculate the center between the eyes for face alignment\n",
    "    eye_center = np.mean([left_eye[3], right_eye[0]], axis=0)\n",
    "    \n",
    "    # Calculate the rotation angle based on the eyes\n",
    "    dY = right_eye[0][1] - left_eye[3][1]\n",
    "    dX = right_eye[0][0] - left_eye[3][0]\n",
    "    angle = np.degrees(np.arctan2(dY, dX))\n",
    "    \n",
    "    # Rotate and align the face using PIL\n",
    "    pil_image = Image.fromarray(test_image)\n",
    "    aligned_face = pil_image.rotate(angle, center=tuple(eye_center))\n",
    "    aligned_face = np.array(aligned_face)\n",
    "    \n",
    "    # Compute face encoding for the aligned face\n",
    "    encoding = face_recognition.face_encodings(aligned_face)\n",
    "    return encoding\n",
    "\n",
    "\n",
    "# Specify the path to the folder containing images of the person\n",
    "folder_path = target\n",
    "\n",
    "# Get the average face encoding from the folder\n",
    "person_average_encoding = [get_average_face_embedding_from_folder(folder_path)]\n",
    "person_average_encoding[0]*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T09:25:51.362318558Z",
     "start_time": "2023-08-12T09:25:49.434115957Z"
    }
   },
   "id": "e068cd302dd7d1f2"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-2.17924878e+01,  8.10547546e+00,  1.02104664e+01, -4.20056097e+00,\n       -4.86861765e+00, -8.82931277e+00, -3.65776531e+00, -5.69343902e+00,\n        8.62849280e+00, -1.60247505e+01,  2.08568543e+01, -4.19502705e+00,\n       -1.57873005e+01, -4.32924554e+00, -2.43294854e+00,  7.38286525e+00,\n       -1.60250574e+01, -1.25346035e+01, -4.88156751e+00, -8.12901929e+00,\n        6.84820116e+00,  3.16068977e+00, -1.51167084e+00,  2.84017678e+00,\n       -1.59982011e+01, -4.04128939e+01, -7.98874944e+00, -1.11144178e+01,\n        4.98868749e+00, -7.25342557e+00,  2.61639431e-01, -4.74382425e-01,\n       -1.03774011e+01,  5.70997782e-01, -2.04399340e+00,  1.03287391e+01,\n       -3.01408898e+00, -2.84722708e+00,  1.96305349e+01, -2.91426647e+00,\n       -1.89502090e+01, -3.69546525e+00,  1.01589322e+01,  2.90886670e+01,\n        1.88273862e+01,  6.91570863e+00,  2.24495698e+00, -9.62567180e+00,\n        9.27939191e+00, -1.60009965e+01,  6.30565137e+00,  1.24283493e+01,\n        7.75592476e+00,  8.59726667e+00,  1.00734711e+01, -1.33367300e+01,\n        3.24872658e+00,  6.60386086e+00, -1.90486833e+01,  8.10394585e+00,\n        2.37759110e+00, -8.23727995e+00,  1.26069039e-01, -1.12065636e+00,\n        1.78211331e+01,  8.31129178e+00, -9.81213078e+00, -1.10286653e+01,\n        1.50470659e+01, -2.40264669e+01, -6.34038374e+00,  5.21776080e+00,\n       -8.64686072e+00, -2.03128695e+01, -2.61228502e+01,  2.42547840e+00,\n        3.53472471e+01,  2.26865917e+01, -1.07082359e+01,  3.88578251e+00,\n        6.67508878e-01, -1.03104711e+01,  1.73182711e+01,  1.59215882e+01,\n       -1.11763492e+01, -1.56383123e+00, -7.12315291e+00,  7.84726143e+00,\n        1.69660747e+01,  5.09135574e+00, -5.94137311e+00,  1.37268215e+01,\n        1.39423274e-01,  4.58157435e+00,  2.64346041e+00,  2.58029122e+00,\n       -1.84397832e+01,  4.72125933e+00, -1.11232914e+01, -3.62718217e+00,\n        6.63144290e+00, -3.94139439e+00,  3.01523656e+00,  1.19907163e+01,\n       -1.28046781e+01,  1.48467585e+01, -1.37070697e+00, -2.02637296e+00,\n       -7.37926085e-01,  5.42301908e+00, -7.76104257e+00, -4.52006496e+00,\n        9.82352346e+00, -1.52661532e+01,  1.56555876e+01,  2.08629191e+01,\n        5.19328266e+00,  1.87981367e+01,  1.50019124e+01,  1.65967532e+00,\n        3.91829237e+00, -2.95015052e-01, -1.92427427e+01,  3.10579489e-02,\n        1.40089579e+00, -2.32392736e+00,  1.45520478e+01,  1.49488095e+00])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_encodings = get_face_embedding_from_test_image('/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10010/10010_8000.jpg')\n",
    "\n",
    "test_encodings[0]*100"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T09:26:56.605709317Z",
     "start_time": "2023-08-12T09:26:56.437992654Z"
    }
   },
   "id": "496f02f59257aeba"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "test_encodings"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T09:20:09.087297503Z",
     "start_time": "2023-08-12T09:20:09.075134939Z"
    }
   },
   "id": "956a18f94ba677c5"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def similarity_comparison(person_average_encoding, test_encodings):\n",
    "    euclidean_distance = np.linalg.norm(person_average_encoding[0] - test_encodings[0])\n",
    "    \n",
    "    cosine_similarity = np.dot(person_average_encoding[0], test_encodings[0]) / (np.linalg.norm(person_average_encoding[0]) * np.linalg.norm(test_encodings[0]))\n",
    "    \n",
    "    print(f\"Euclidean Distance: {euclidean_distance}\")\n",
    "    print(f\"Cosine Similarity: {cosine_similarity}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T10:34:45.587618931Z",
     "start_time": "2023-08-12T10:34:45.545443445Z"
    }
   },
   "id": "a7268b325b17eecb"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def encode_embedding_to_json(embedding):\n",
    "    serializable_embedding = embedding.tolist()\n",
    "    encoded_json = json.dumps(serializable_embedding)\n",
    "    return encoded_json\n",
    "\n",
    "def decode_embedding_from_json(encoded_json):\n",
    "    serializable_embedding = json.loads(encoded_json)\n",
    "    embedding = np.array(serializable_embedding)\n",
    "    return embedding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59b33497fc7a5047"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded JSON: [-0.2067381665110588, 0.08201986710940089, 0.0728124100714922, -0.04580768779851496, -0.05902766888695104, -0.05754665458308799, -0.02419475732105119, -0.06247770520193236, 0.1121629641524383, -0.12578524223395757, 0.18459004908800125, -0.022579674742051532, -0.19288987985679082, -0.039845642633736134, -0.031411695992574096, 0.07718150211232049, -0.13839714974164963, -0.13992971128651074, -0.04934393893927336, -0.0802936279880149, 0.06840957701206207, 0.01214499318406784, -0.03481519416839417, 0.02809305316103356, -0.14287518284150533, -0.3829967656305858, -0.0644887126982212, -0.09555512507046972, 0.04277209545086537, -0.08662761614790984, 0.0052017406560480595, 0.008669873466715217, -0.12931381804602488, -0.005859454361987966, -0.02670197275334171, 0.12330018409660884, -0.016602726187556982, -0.029117680054956248, 0.1749506848199027, -0.0043868739157915115, -0.156813311789717, -0.0509390514343977, 0.08069876847522599, 0.28170729747840334, 0.17778143073831285, 0.058497726917266846, 0.03306377413017409, -0.07748198775308472, 0.08273942236389432, -0.18378664766039168, 0.040835079337869375, 0.1159785155739103, 0.08987933077982493, 0.08697094209492207, 0.10095196164080075, -0.1430706466947283, 0.04055788727211101, 0.04104279553783791, -0.18830917882067816, 0.07898005577070373, 0.02253233954044325, -0.06476551626941987, -0.019577581901103258, -0.01868900497044836, 0.19047182372638158, 0.07259579042771033, -0.085162203758955, -0.1081472917326859, 0.14767499853457725, -0.23561348340341023, -0.06882962025702, 0.04388867252107177, -0.06480008576597486, -0.17958009296229907, -0.260567344725132, 0.020150942461831228, 0.35373266679900034, 0.2246211086000715, -0.12787148622529848, 0.04228033764021737, -0.022621252108365297, -0.09443214934851442, 0.1427740380167961, 0.10045040214234698, -0.11108772456645966, 0.020458654833159277, -0.09378606347101075, 0.06088358762540987, 0.18320519157818385, 0.06007667418037142, -0.04052278958261013, 0.15854951100690023, 0.01316269813105464, 0.04271553782746196, 0.0357413015860532, 0.03399362441684518, -0.15397560064281737, 0.029904732281076058, -0.09939394226031643, -0.05513028906924384, 0.07393325466130461, -0.0675945348505463, 0.04039244167506695, 0.10823467373847961, -0.15402909900460923, 0.14243638355817115, -0.020699236425571144, -0.0013200800998934678, -0.00983280608696597, 0.05497291524495397, -0.09715742245316505, -0.037835095676460435, 0.12029770495636123, -0.18150776198932103, 0.13923651964536735, 0.2118458098598889, 0.026264478718595847, 0.1562322931630271, 0.12524742845978057, 0.025204610279096023, 0.02208717493340373, -0.007632173398243529, -0.1649286486208439, -0.025348887433730333, -0.00803752216909613, -0.027728522329458168, 0.10632066801190376, 0.03677500950704728]\n",
      "Decoded embedding: [-0.20673817  0.08201987  0.07281241 -0.04580769 -0.05902767 -0.05754665\n",
      " -0.02419476 -0.06247771  0.11216296 -0.12578524  0.18459005 -0.02257967\n",
      " -0.19288988 -0.03984564 -0.0314117   0.0771815  -0.13839715 -0.13992971\n",
      " -0.04934394 -0.08029363  0.06840958  0.01214499 -0.03481519  0.02809305\n",
      " -0.14287518 -0.38299677 -0.06448871 -0.09555513  0.0427721  -0.08662762\n",
      "  0.00520174  0.00866987 -0.12931382 -0.00585945 -0.02670197  0.12330018\n",
      " -0.01660273 -0.02911768  0.17495068 -0.00438687 -0.15681331 -0.05093905\n",
      "  0.08069877  0.2817073   0.17778143  0.05849773  0.03306377 -0.07748199\n",
      "  0.08273942 -0.18378665  0.04083508  0.11597852  0.08987933  0.08697094\n",
      "  0.10095196 -0.14307065  0.04055789  0.0410428  -0.18830918  0.07898006\n",
      "  0.02253234 -0.06476552 -0.01957758 -0.018689    0.19047182  0.07259579\n",
      " -0.0851622  -0.10814729  0.147675   -0.23561348 -0.06882962  0.04388867\n",
      " -0.06480009 -0.17958009 -0.26056734  0.02015094  0.35373267  0.22462111\n",
      " -0.12787149  0.04228034 -0.02262125 -0.09443215  0.14277404  0.1004504\n",
      " -0.11108772  0.02045865 -0.09378606  0.06088359  0.18320519  0.06007667\n",
      " -0.04052279  0.15854951  0.0131627   0.04271554  0.0357413   0.03399362\n",
      " -0.1539756   0.02990473 -0.09939394 -0.05513029  0.07393325 -0.06759453\n",
      "  0.04039244  0.10823467 -0.1540291   0.14243638 -0.02069924 -0.00132008\n",
      " -0.00983281  0.05497292 -0.09715742 -0.0378351   0.1202977  -0.18150776\n",
      "  0.13923652  0.21184581  0.02626448  0.15623229  0.12524743  0.02520461\n",
      "  0.02208717 -0.00763217 -0.16492865 -0.02534889 -0.00803752 -0.02772852\n",
      "  0.10632067  0.03677501]\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\n",
    "# Example usage:\n",
    "original_embedding = person_average_encoding[0] # Replace with your 128-dimensional embedding\n",
    "\n",
    "# Encode the embedding to a JSON string\n",
    "encoded_json = encode_embedding_to_json(original_embedding)\n",
    "print(\"Encoded JSON:\", encoded_json)\n",
    "\n",
    "# Decode the JSON string back to the original embedding\n",
    "decoded_embedding = decode_embedding_from_json(encoded_json)\n",
    "print(\"Decoded embedding:\", decoded_embedding)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-12T10:36:49.401612721Z"
    }
   },
   "id": "aa52089ad7e43c0"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distance: 0.0\n",
      "Cosine Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "similarity_comparison(original_embedding, decoded_embedding)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T10:36:50.223970270Z",
     "start_time": "2023-08-12T10:36:50.220008725Z"
    }
   },
   "id": "9babd18bf2b54ac"
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "'/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/Face_Recog'"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T11:09:13.679818287Z",
     "start_time": "2023-08-12T11:09:13.633394511Z"
    }
   },
   "id": "5f9c81a3db5b927"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading Training Videos...\n",
      "\n",
      "Downloading video of 10019...\n",
      "Downloaded video of 10019...\n",
      "\n",
      "Raw videos downloaded for training.\n",
      "\n",
      "Extracting Frames from Videos...\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100191000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100192000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100196000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100197000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/100199000.jpg\n",
      "Data/Facial_Recog/Raw_DataStore/FacialRecog_TargetFrames/10019/1001910000.jpg\n",
      "Frames Extracted\n",
      "\n",
      "Connected to the MySQL database!\n",
      "...Facial_Encoding_Recorded...\n",
      "\n",
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('/home/manz/Desktop/My Stuffs/Work Stuffs/Python Envs/HyperSpace/ComputerVision/')\n",
    "from DataPreproc.extractFaceEncodings import get_embedding_train\n",
    "from Database_Connect.Load_Users import insert_user_encodings\n",
    "userID = '10019'\n",
    "\n",
    "face_encodings = get_embedding_train([userID])\n",
    "insert_user_encodings(userID, face_encodings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T12:09:21.676177467Z",
     "start_time": "2023-08-12T12:09:03.151259079Z"
    }
   },
   "id": "7758fa68093f39a1"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connected to the MySQL database!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Connection closed.\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "from Database_Connect.utils import DB_Disconnect, DB_Connect\n",
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "def RealTime_FacialRecognition():\n",
    "    # Connect to the MySQL database\n",
    "    connection = DB_Connect()\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    try:\n",
    "        # Fetch user information and face encodings\n",
    "        fetch_query = \"\"\"\n",
    "            SELECT UserID, FirstName, LastName, face_encodings FROM Users;\n",
    "        \"\"\"\n",
    "        cursor.execute(fetch_query)\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        user_ids = []\n",
    "        first_names = []\n",
    "        last_names = []\n",
    "        face_encodings = []\n",
    "\n",
    "        for row in results:\n",
    "            user_ids.append(row[0])\n",
    "            first_names.append(row[1])\n",
    "            last_names.append(row[2])\n",
    "            face_encoding = np.fromstring(row[3].strip('[]'), sep=',')\n",
    "            face_encodings.append(face_encoding)\n",
    "\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error: {err}\")\n",
    "        cursor.close()\n",
    "        DB_Disconnect(connection)\n",
    "        return\n",
    "\n",
    "    # Set a threshold for face recognition\n",
    "    similarity_threshold = 0.6\n",
    "\n",
    "    # Open a video capture\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Find face locations and encodings in the current frame\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "        face_encodings_frame = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "        for (top, right, bottom, left), encoding in zip(face_locations, face_encodings_frame):\n",
    "            # Compare the encoding with known face encodings\n",
    "            distances = face_recognition.face_distance(face_encodings, encoding)\n",
    "            min_distance_idx = np.argmin(distances)\n",
    "\n",
    "            if distances[min_distance_idx] <= similarity_threshold:\n",
    "                user_id = user_ids[min_distance_idx]\n",
    "                first_name = first_names[min_distance_idx]\n",
    "                last_name = last_names[min_distance_idx]\n",
    "\n",
    "                # Display user information on the frame\n",
    "                label = f\"{first_name} {last_name} (ID: {user_id})\"\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                cv2.putText(frame, label, (left, top - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Close the database connection\n",
    "    cursor.close()\n",
    "    DB_Disconnect(connection)\n",
    "    print('done')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    RealTime_FacialRecognition()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-12T12:15:35.572724619Z",
     "start_time": "2023-08-12T12:15:24.324120138Z"
    }
   },
   "id": "d8b09be7d4f5ba5a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ca718aa8e10da381"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
